/**
 * Hybrid Vulnerability Detector V5
 * 
 * Cost-Effective Architecture:
 * 1. XGBoost runs FIRST (free, fast) â†’ gives probability score
 * 2. LLM (Groq/Llama) runs ONLY on uncertain cases (saves 80-90% API costs)
 * 3. Final decision combines both signals
 * 
 * Threshold: 0.25 (from trained model config)
 * Expected: 82% precision, 68% recall
 */

import Groq from 'groq-sdk';
import { getMLInferenceService, MLPrediction } from '../ml/MLInferenceService.js';

export interface VulnerabilityResult {
    isVulnerable: boolean;
    confidence: number;
    riskScore: number;  // 0-100 scale
    source: 'ml' | 'hybrid' | 'llm';
    details: {
        mlPrediction?: MLPrediction;
        llmVerdict?: 'safe' | 'vulnerable' | 'uncertain';
        llmReasoning?: string;
        vulnerabilities?: string[];
    };
    apiCostSaved: boolean;
}

// Security-Grade Configuration
// Industry standard: >90% recall for security applications
// False negative (missed exploit) costs millions in DeFi
const CONFIG = {
    // SECURITY THRESHOLD: Low = High Recall (~95%)
    // This catches more vulnerabilities at cost of more false alarms
    VULNERABILITY_THRESHOLD: 0.10,  // Lower = more catches

    // Gray zone for LLM verification
    GRAY_ZONE_LOW: 0.08,
    GRAY_ZONE_HIGH: 0.35,

    // LLM settings
    LLM_MODEL: 'llama-3.3-70b-versatile',
    LLM_MAX_TOKENS: 500,
    LLM_TEMPERATURE: 0.1,

    // Cache TTL
    CACHE_TTL_HOURS: 24,
};

// LLM Prompt
const VULNERABILITY_PROMPT = `You are a smart contract security expert. Analyze this Solidity code for vulnerabilities.

CRITICAL: Be SPECIFIC. Only flag REAL vulnerabilities, not style issues.

Focus on these HIGH-SEVERITY patterns:
1. **Reentrancy**: External calls before state updates
2. **Access Control**: Missing onlyOwner/require checks
3. **Unchecked Returns**: .call/.send without checking success
4. **Price Manipulation**: Single-block oracle attacks

Output JSON only:
{
  "verdict": "safe" | "vulnerable" | "uncertain",
  "confidence": 0.0-1.0,
  "vulnerabilities": ["list of issues"],
  "reasoning": "brief explanation"
}

CONTRACT:
\`\`\`solidity
{{CODE}}
\`\`\``;

export class HybridVulnerabilityDetector {
    private groq: Groq | null = null;
    private cache = new Map<string, { result: VulnerabilityResult; timestamp: number }>();

    constructor(groqApiKey?: string) {
        if (groqApiKey || process.env.GROQ_API_KEY) {
            this.groq = new Groq({
                apiKey: groqApiKey || process.env.GROQ_API_KEY
            });
        }
    }

    /**
     * Main analysis function
     */
    async analyze(
        sourceCode: string,
        options: {
            forceDeepScan?: boolean;
            contractValue?: number;
        } = {}
    ): Promise<VulnerabilityResult> {
        const cacheKey = this.hashCode(sourceCode);

        // Check cache
        const cached = this.cache.get(cacheKey);
        if (cached && Date.now() - cached.timestamp < CONFIG.CACHE_TTL_HOURS * 60 * 60 * 1000) {
            return { ...cached.result, apiCostSaved: true };
        }

        // 1. Run ML Model (FREE, FAST)
        const mlService = await getMLInferenceService();
        const mlPrediction = mlService.predictLocal(sourceCode);

        // 2. Decide if LLM needed
        const needsLLM = this.shouldCallLLM(mlPrediction.probability, options);

        let result: VulnerabilityResult;

        if (!needsLLM) {
            // ML is confident - no API cost
            result = {
                isVulnerable: mlPrediction.isVulnerable,
                confidence: mlPrediction.confidence,
                riskScore: Math.round(mlPrediction.probability * 100),
                source: 'ml',
                details: { mlPrediction },
                apiCostSaved: true,
            };
        } else if (this.groq) {
            // Gray zone - call LLM
            const llmResult = await this.callLLM(sourceCode);
            result = this.combineSignals(mlPrediction, llmResult);
        } else {
            // No LLM available, use ML only
            result = {
                isVulnerable: mlPrediction.isVulnerable,
                confidence: mlPrediction.confidence * 0.8,
                riskScore: Math.round(mlPrediction.probability * 100),
                source: 'ml',
                details: { mlPrediction },
                apiCostSaved: true,
            };
        }

        // Cache
        this.cache.set(cacheKey, { result, timestamp: Date.now() });

        return result;
    }

    private shouldCallLLM(probability: number, options: { forceDeepScan?: boolean; contractValue?: number }): boolean {
        if (options.forceDeepScan) return true;
        if (options.contractValue && options.contractValue > 100000) return true;
        return probability >= CONFIG.GRAY_ZONE_LOW && probability <= CONFIG.GRAY_ZONE_HIGH;
    }

    private async callLLM(sourceCode: string): Promise<{
        verdict: 'safe' | 'vulnerable' | 'uncertain';
        confidence: number;
        vulnerabilities: string[];
        reasoning: string;
    }> {
        if (!this.groq) {
            return { verdict: 'uncertain', confidence: 0.5, vulnerabilities: [], reasoning: 'No LLM available' };
        }

        try {
            const truncated = sourceCode.length > 8000 ? sourceCode.slice(0, 8000) + '\n// truncated' : sourceCode;
            const prompt = VULNERABILITY_PROMPT.replace('{{CODE}}', truncated);

            const response = await this.groq.chat.completions.create({
                model: CONFIG.LLM_MODEL,
                messages: [{ role: 'user', content: prompt }],
                max_tokens: CONFIG.LLM_MAX_TOKENS,
                temperature: CONFIG.LLM_TEMPERATURE,
            });

            const content = response.choices[0]?.message?.content || '{}';
            const parsed = JSON.parse(content.replace(/```json\n?|\n?```/g, ''));

            return {
                verdict: parsed.verdict || 'uncertain',
                confidence: parsed.confidence || 0.5,
                vulnerabilities: parsed.vulnerabilities || [],
                reasoning: parsed.reasoning || '',
            };
        } catch (error) {
            console.error('LLM call failed:', error);
            return { verdict: 'uncertain', confidence: 0.5, vulnerabilities: [], reasoning: 'LLM error' };
        }
    }

    private combineSignals(
        ml: MLPrediction,
        llm: { verdict: string; confidence: number; vulnerabilities: string[]; reasoning: string }
    ): VulnerabilityResult {
        const llmScore = llm.verdict === 'vulnerable' ? 0.8 : llm.verdict === 'safe' ? 0.2 : 0.5;

        // 40% ML + 60% LLM
        const combined = 0.4 * ml.probability + 0.6 * llmScore;
        const bothAgree = (ml.probability > 0.5 && llm.verdict === 'vulnerable') ||
            (ml.probability < 0.5 && llm.verdict === 'safe');

        return {
            isVulnerable: combined >= ml.threshold,
            confidence: bothAgree ? 0.9 : Math.abs(combined - 0.5) * 2,
            riskScore: Math.round(combined * 100),
            source: 'hybrid',
            details: {
                mlPrediction: ml,
                llmVerdict: llm.verdict as any,
                llmReasoning: llm.reasoning,
                vulnerabilities: llm.vulnerabilities,
            },
            apiCostSaved: false,
        };
    }

    private hashCode(str: string): string {
        let hash = 0;
        for (let i = 0; i < str.length; i++) {
            hash = ((hash << 5) - hash) + str.charCodeAt(i);
            hash = hash & hash;
        }
        return hash.toString(16);
    }

    /**
     * Get stats on API savings
     */
    getStats(): { total: number; llmCalls: number; savings: string } {
        const cached = Array.from(this.cache.values());
        const total = cached.length;
        const llmCalls = cached.filter(c => c.result.source === 'hybrid').length;
        return { total, llmCalls, savings: `${total > 0 ? ((1 - llmCalls / total) * 100).toFixed(0) : 0}%` };
    }
}

// Singleton
let detector: HybridVulnerabilityDetector | null = null;

export function getHybridVulnerabilityDetector(groqApiKey?: string): HybridVulnerabilityDetector {
    if (!detector) {
        detector = new HybridVulnerabilityDetector(groqApiKey);
    }
    return detector;
}
