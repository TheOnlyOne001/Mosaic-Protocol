{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# üõ°Ô∏è Mosaic Protocol - Smart Contract Vulnerability Classifier V2\n",
                "\n",
                "**Dataset:** SmartBugs Curated (248 samples)\n",
                "**Features:** 55 hybrid Slither-ML features\n",
                "**Model:** XGBoost with SMOTE balancing\n",
                "\n",
                "---"
            ],
            "metadata": {
                "id": "header"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 1Ô∏è‚É£ Setup & Mount Google Drive"
            ],
            "metadata": {
                "id": "setup"
            }
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "mount_drive"
            },
            "outputs": [],
            "source": [
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "import os\n",
                "OUTPUT_DIR = '/content/drive/MyDrive/mosaic-ml'\n",
                "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
                "print(f\"‚úÖ Output directory: {OUTPUT_DIR}\")"
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "# Install dependencies\n",
                "!pip install xgboost scikit-learn imbalanced-learn onnxmltools onnx onnxruntime matplotlib seaborn --quiet\n",
                "print(\"‚úÖ Dependencies installed\")"
            ],
            "metadata": {
                "id": "install_deps"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 2Ô∏è‚É£ Load SmartBugs Training Data"
            ],
            "metadata": {
                "id": "load_data"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import json\n",
                "import gzip\n",
                "import numpy as np\n",
                "from pathlib import Path\n",
                "\n",
                "DATA_DIR = '/content/drive/MyDrive/mosaic-ml'\n",
                "\n",
                "# Find smartbugs training file\n",
                "data_files = list(Path(DATA_DIR).glob('smartbugs_training_*.json*'))\n",
                "if not data_files:\n",
                "    # Fallback to old format\n",
                "    data_files = list(Path(DATA_DIR).glob('training_data_*.json*'))\n",
                "\n",
                "if not data_files:\n",
                "    raise FileNotFoundError(f\"No training data in {DATA_DIR}\")\n",
                "\n",
                "data_file = sorted(data_files)[-1]\n",
                "print(f\"üìÇ Loading: {data_file.name}\")\n",
                "\n",
                "if str(data_file).endswith('.gz'):\n",
                "    with gzip.open(data_file, 'rt', encoding='utf-8') as f:\n",
                "        data = json.load(f)\n",
                "else:\n",
                "    with open(data_file, 'r') as f:\n",
                "        data = json.load(f)\n",
                "\n",
                "print(f\"\"\"\\nüìä Dataset Summary:\n",
                "   Total samples: {data['metadata']['totalSamples']:,}\n",
                "   Features: {data['metadata']['featureCount']}\n",
                "   Labels: {data['metadata']['labelDistribution']}\n",
                "\"\"\")\n",
                "\n",
                "if 'vulnerabilityTypes' in data['metadata']:\n",
                "    print(\"üè∑Ô∏è Vulnerability types:\")\n",
                "    for vtype, count in sorted(data['metadata']['vulnerabilityTypes'].items(), key=lambda x: -x[1])[:5]:\n",
                "        print(f\"   {vtype}: {count}\")"
            ],
            "metadata": {
                "id": "load_json"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Convert to numpy arrays\n",
                "def to_arrays(samples):\n",
                "    X = np.array([s['features'] for s in samples], dtype=np.float32)\n",
                "    y = np.array([s['label'] for s in samples], dtype=np.int32)\n",
                "    return X, y\n",
                "\n",
                "X_train, y_train = to_arrays(data['train'])\n",
                "X_val, y_val = to_arrays(data['validation'])\n",
                "X_test, y_test = to_arrays(data['test'])\n",
                "\n",
                "print(f\"\"\"üìê Array shapes:\n",
                "   Train: {X_train.shape} (safe: {(y_train==0).sum()}, vuln: {(y_train==1).sum()})\n",
                "   Val:   {X_val.shape} (safe: {(y_val==0).sum()}, vuln: {(y_val==1).sum()})\n",
                "   Test:  {X_test.shape} (safe: {(y_test==0).sum()}, vuln: {(y_test==1).sum()})\n",
                "\"\"\")\n",
                "\n",
                "feature_names = data['metadata']['featureNames']\n",
                "print(f\"Feature names ({len(feature_names)}): {feature_names[:5]}...\")"
            ],
            "metadata": {
                "id": "convert_arrays"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 3Ô∏è‚É£ Handle Class Imbalance with SMOTE"
            ],
            "metadata": {
                "id": "smote"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "from imblearn.over_sampling import SMOTE\n",
                "\n",
                "# Apply SMOTE to training data only\n",
                "print(\"‚öñÔ∏è Before SMOTE:\")\n",
                "print(f\"   Safe: {(y_train==0).sum()}, Vulnerable: {(y_train==1).sum()}\")\n",
                "\n",
                "smote = SMOTE(random_state=42)\n",
                "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
                "\n",
                "print(\"\\n‚úÖ After SMOTE:\")\n",
                "print(f\"   Safe: {(y_train_balanced==0).sum()}, Vulnerable: {(y_train_balanced==1).sum()}\")"
            ],
            "metadata": {
                "id": "apply_smote"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 4Ô∏è‚É£ Train XGBoost Model"
            ],
            "metadata": {
                "id": "train"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "from xgboost import XGBClassifier\n",
                "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Train model on balanced data\n",
                "model = XGBClassifier(\n",
                "    n_estimators=100,\n",
                "    max_depth=4,\n",
                "    learning_rate=0.1,\n",
                "    eval_metric='aucpr',\n",
                "    use_label_encoder=False,\n",
                "    random_state=42,\n",
                "    verbosity=1\n",
                ")\n",
                "\n",
                "print(\"üöÄ Training XGBoost on SMOTE-balanced data...\")\n",
                "model.fit(\n",
                "    X_train_balanced, y_train_balanced,\n",
                "    eval_set=[(X_val, y_val)],\n",
                "    verbose=20\n",
                ")\n",
                "print(\"‚úÖ Training complete!\")"
            ],
            "metadata": {
                "id": "train_xgb"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 5Ô∏è‚É£ Evaluate Model"
            ],
            "metadata": {
                "id": "evaluate"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Get predictions\n",
                "y_pred = model.predict(X_test)\n",
                "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
                "\n",
                "print(\"üìä Classification Report (default threshold=0.5):\")\n",
                "print(classification_report(y_test, y_pred, target_names=['Safe', 'Vulnerable']))\n",
                "\n",
                "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
                "print(f\"üéØ ROC-AUC Score: {roc_auc:.4f}\")"
            ],
            "metadata": {
                "id": "eval_basic"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Confusion Matrix\n",
                "plt.figure(figsize=(8, 6))\n",
                "cm = confusion_matrix(y_test, y_pred)\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
                "            xticklabels=['Safe', 'Vulnerable'],\n",
                "            yticklabels=['Safe', 'Vulnerable'])\n",
                "plt.title('Confusion Matrix')\n",
                "plt.ylabel('Actual')\n",
                "plt.xlabel('Predicted')\n",
                "plt.tight_layout()\n",
                "plt.savefig(f\"{OUTPUT_DIR}/confusion_matrix_v2.png\")\n",
                "plt.show()"
            ],
            "metadata": {
                "id": "confusion_matrix"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Optimize threshold for high recall\n",
                "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
                "\n",
                "target_recall = 0.85\n",
                "idx = np.where(recall >= target_recall)[0]\n",
                "if len(idx) > 0:\n",
                "    best_idx = idx[-1]\n",
                "    optimal_threshold = thresholds[best_idx] if best_idx < len(thresholds) else 0.5\n",
                "    print(f\"üéØ For {target_recall:.0%} recall on vulnerabilities:\")\n",
                "    print(f\"   Optimal threshold: {optimal_threshold:.3f}\")\n",
                "    print(f\"   Precision: {precision[best_idx]:.3f}\")\n",
                "else:\n",
                "    optimal_threshold = 0.3\n",
                "    best_idx = 0\n",
                "    print(f\"‚ö†Ô∏è Using default threshold: {optimal_threshold}\")\n",
                "\n",
                "y_pred_opt = (y_pred_proba >= optimal_threshold).astype(int)\n",
                "print(\"\\nüìä Classification Report (optimized threshold):\")\n",
                "print(classification_report(y_test, y_pred_opt, target_names=['Safe', 'Vulnerable']))"
            ],
            "metadata": {
                "id": "optimize_threshold"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 6Ô∏è‚É£ Feature Importance"
            ],
            "metadata": {
                "id": "feature_importance"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "importances = model.feature_importances_\n",
                "indices = np.argsort(importances)[::-1][:15]\n",
                "\n",
                "plt.figure(figsize=(12, 6))\n",
                "plt.bar(range(15), importances[indices])\n",
                "plt.xticks(range(15), [feature_names[i] for i in indices], rotation=45, ha='right')\n",
                "plt.title('Top 15 Most Important Features')\n",
                "plt.tight_layout()\n",
                "plt.savefig(f\"{OUTPUT_DIR}/feature_importance_v2.png\")\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nüîù Top 10 Features:\")\n",
                "for i, idx_feat in enumerate(indices[:10]):\n",
                "    print(f\"   {i+1}. {feature_names[idx_feat]}: {importances[idx_feat]:.4f}\")"
            ],
            "metadata": {
                "id": "feature_imp"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 7Ô∏è‚É£ Save Model (Pickle - Simple & Works)"
            ],
            "metadata": {
                "id": "export"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import joblib\n",
                "\n",
                "# Save as pickle (most reliable)\n",
                "model_path = f\"{OUTPUT_DIR}/vulnerability_classifier_v2.pkl\"\n",
                "joblib.dump(model, model_path)\n",
                "print(f\"‚úÖ Saved model: {model_path}\")\n",
                "\n",
                "# Save metadata\n",
                "model_metadata = {\n",
                "    'model_name': 'vulnerability_classifier_v2',\n",
                "    'model_type': 'XGBoost',\n",
                "    'created_at': str(np.datetime64('now')),\n",
                "    'num_features': len(feature_names),\n",
                "    'feature_names': feature_names,\n",
                "    'classes': ['safe', 'vulnerable'],\n",
                "    'optimal_threshold': float(optimal_threshold),\n",
                "    'metrics': {\n",
                "        'roc_auc': float(roc_auc),\n",
                "        'accuracy': float((y_pred == y_test).mean()),\n",
                "        'recall_vulnerable': float(recall[best_idx]) if len(idx) > 0 else 0,\n",
                "        'precision_vulnerable': float(precision[best_idx]) if len(idx) > 0 else 0,\n",
                "    },\n",
                "    'training_samples': int(len(y_train_balanced)),\n",
                "}\n",
                "\n",
                "metadata_path = f\"{OUTPUT_DIR}/model_metadata_v2.json\"\n",
                "with open(metadata_path, 'w') as f:\n",
                "    json.dump(model_metadata, f, indent=2)\n",
                "print(f\"‚úÖ Saved metadata: {metadata_path}\")\n",
                "\n",
                "print(\"\\nüìã Model Metadata:\")\n",
                "for k, v in model_metadata.items():\n",
                "    if k not in ['feature_names']:\n",
                "        print(f\"   {k}: {v}\")"
            ],
            "metadata": {
                "id": "save_model"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## ‚úÖ Training Complete!\n",
                "\n",
                "**Files saved:**\n",
                "- `vulnerability_classifier_v2.pkl` - XGBoost model\n",
                "- `model_metadata_v2.json` - Configuration\n",
                "- `confusion_matrix_v2.png`\n",
                "- `feature_importance_v2.png`\n",
                "\n",
                "**Next:** Download files and place in `backend/src/agents/defi-safety/ml/models/`"
            ],
            "metadata": {
                "id": "complete"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "print(\"\\nüìÅ Output files:\")\n",
                "for f in os.listdir(OUTPUT_DIR):\n",
                "    if 'v2' in f or 'smartbugs' in f:\n",
                "        size = os.path.getsize(f\"{OUTPUT_DIR}/{f}\") / 1024\n",
                "        print(f\"   {f} ({size:.1f} KB)\")"
            ],
            "metadata": {
                "id": "list_files"
            },
            "execution_count": null,
            "outputs": []
        }
    ]
}